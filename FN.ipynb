{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3742576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df1a07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"fake_news.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee4fed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20800, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b631abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20800 entries, 0 to 20799\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      20800 non-null  int64 \n",
      " 1   title   20242 non-null  object\n",
      " 2   author  18843 non-null  object\n",
      " 3   text    20761 non-null  object\n",
      " 4   label   20800 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 812.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cecd3809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f461820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5df4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1421e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['title'] + '' + data['text'] # Combine 'title' and 'text' columns into 'content'\n",
    "data = data.drop(['title', 'text'], axis=1)          # Drop 'title' and 'text' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85bca568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>1</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>0</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>1</td>\n",
       "      <td>Why the Truth Might Get You FiredWhy the Truth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>1</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>1</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author  label  \\\n",
       "0       Darrell Lucus      1   \n",
       "1     Daniel J. Flynn      0   \n",
       "2  Consortiumnews.com      1   \n",
       "3     Jessica Purkiss      1   \n",
       "4      Howard Portnoy      1   \n",
       "\n",
       "                                             content  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...  \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...  \n",
       "2  Why the Truth Might Get You FiredWhy the Truth...  \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...  \n",
       "4  Iranian woman jailed for fictional unpublished...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "933dd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36b83fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jajal\\AppData\\Local\\Temp\\ipykernel_21664\\3602057189.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['content'] = data['content'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "\n",
    "data['content'] = data['content'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aa61e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jajal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c0ed860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Obtaining dependency information for textblob from https://files.pythonhosted.org/packages/1e/d6/40aa5aead775582ea0cf35870e5a3f16fab4b967f1ad2debe675f673f923/textblob-0.19.0-py3-none-any.whl.metadata\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting nltk>=3.9 (from textblob)\n",
      "  Obtaining dependency information for nltk>=3.9 from https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\jajal\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\jajal\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jajal\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jajal\\anaconda3\\lib\\site-packages (from nltk>=3.9->textblob) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jajal\\anaconda3\\lib\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/624.3 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/624.3 kB ? eta -:--:--\n",
      "   - ------------------------------------- 30.7/624.3 kB 187.9 kB/s eta 0:00:04\n",
      "   - ------------------------------------- 30.7/624.3 kB 187.9 kB/s eta 0:00:04\n",
      "   - ------------------------------------- 30.7/624.3 kB 187.9 kB/s eta 0:00:04\n",
      "   -- ------------------------------------ 41.0/624.3 kB 131.3 kB/s eta 0:00:05\n",
      "   -- ------------------------------------ 41.0/624.3 kB 131.3 kB/s eta 0:00:05\n",
      "   --- ----------------------------------- 61.4/624.3 kB 156.1 kB/s eta 0:00:04\n",
      "   ---- ---------------------------------- 71.7/624.3 kB 163.8 kB/s eta 0:00:04\n",
      "   ----- --------------------------------- 92.2/624.3 kB 194.1 kB/s eta 0:00:03\n",
      "   ------- ------------------------------ 122.9/624.3 kB 232.7 kB/s eta 0:00:03\n",
      "   ---------- --------------------------- 174.1/624.3 kB 299.5 kB/s eta 0:00:02\n",
      "   --------------- ---------------------- 256.0/624.3 kB 413.7 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 430.1/624.3 kB 656.0 kB/s eta 0:00:01\n",
      "   -------------------------------------  614.4/624.3 kB 879.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 624.3/624.3 kB 873.5 kB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.1/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.5 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.5 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.8 MB/s eta 0:00:00\n",
      "Installing collected packages: nltk, textblob\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "Successfully installed nltk-3.9.1 textblob-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "910e2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7b15dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jajal\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95e6bd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    house dem aide didnt even see comeys letter ja...\n",
       "1    flynn hillary clinton big woman campus breitba...\n",
       "2    truth might get firedwhy truth might get fired...\n",
       "3    15 civilian killed single u airstrike identifi...\n",
       "4    iranian woman jailed fictional unpublished sto...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import Word\n",
    "data['content'] = data['content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "data['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e49c7254",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['content']\n",
    "y=data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d10a636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=45,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53caf44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14560,)\n",
      "(6240,)\n",
      "(14560,)\n",
      "(6240,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7cd4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0624a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "\n",
    "tfidf_vect.fit(data['content'])\n",
    "\n",
    "xtrain_tfidf = tfidf_vect.transform(X_train)\n",
    "xtest_tfidf = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d35235",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "1.Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10b154cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      3116\n",
      "           1       0.94      0.95      0.94      3124\n",
      "\n",
      "    accuracy                           0.94      6240\n",
      "   macro avg       0.94      0.94      0.94      6240\n",
      "weighted avg       0.94      0.94      0.94      6240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import metrics\n",
    "pclf=PassiveAggressiveClassifier()\n",
    "pclf.fit(xtrain_tfidf,y_train)\n",
    "predictions=pclf.predict(xtest_tfidf)\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ba66355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2919  197]\n",
      " [ 170 2954]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14001e06",
   "metadata": {},
   "source": [
    "# 2.MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20726537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      3116\n",
      "           1       0.94      0.95      0.95      3124\n",
      "\n",
      "    accuracy                           0.95      6240\n",
      "   macro avg       0.95      0.95      0.95      6240\n",
      "weighted avg       0.95      0.95      0.95      6240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpclf=MLPClassifier(hidden_layer_sizes=(256,64,16),\n",
    "                    activation='relu',\n",
    "                    solver='adam')\n",
    "mlpclf.fit(xtrain_tfidf,y_train)\n",
    "predictions=mlpclf.predict(xtest_tfidf)\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3a8fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2932  184]\n",
      " [ 151 2973]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a7a0f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(mlpclf,open(\"fakenews1.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b1d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
